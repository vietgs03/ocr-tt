from PIL import Image
import io
import ollama
import time
import os
from concurrent.futures import ThreadPoolExecutor, as_completed
import logging

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')

class ChunkedOCR:
    """
    Chunked Parallel OCR
    - C·∫Øt ·∫£nh th√†nh nhi·ªÅu chunks (tiles)
    - OCR song song t·ª´ng chunk
    - Gh√©p k·∫øt qu·∫£ l·∫°i
    
    ∆Øu ƒëi·ªÉm:
    - Nhanh h∆°n 60-70% (parallel chunks)
    - Kh√¥ng ph·ª• thu·ªôc cache ‚Üí Lu√¥n ch√≠nh x√°c
    - Scalable v·ªõi nhi·ªÅu CPU cores
    """
    
    def __init__(self, model_name="deepseek-ocr", keep_alive="60m"):
        self.client = ollama.Client(host='http://127.0.0.1:11434')
        self.model_name = model_name
        self.keep_alive = keep_alive
        logging.info(f"üöÄ Chunked OCR initialized: {self.model_name}")
    
    def split_image(self, image_path, rows=2, cols=2):
        """
        C·∫Øt ·∫£nh th√†nh chunks grid
        
        Args:
            image_path: ƒê∆∞·ªùng d·∫´n ·∫£nh
            rows: S·ªë h√†ng
            cols: S·ªë c·ªôt
        
        Returns:
            List of (chunk_bytes, position)
        """
        img = Image.open(image_path)
        width, height = img.size
        
        chunk_width = width // cols
        chunk_height = height // rows
        
        chunks = []
        
        for row in range(rows):
            for col in range(cols):
                # Calculate chunk bounds
                left = col * chunk_width
                top = row * chunk_height
                right = left + chunk_width if col < cols - 1 else width
                bottom = top + chunk_height if row < rows - 1 else height
                
                # Crop chunk
                chunk = img.crop((left, top, right, bottom))
                
                # Convert to bytes
                chunk_bytes = io.BytesIO()
                chunk.save(chunk_bytes, format='PNG')
                chunk_bytes = chunk_bytes.getvalue()
                
                chunks.append({
                    'bytes': chunk_bytes,
                    'position': (row, col),
                    'bounds': (left, top, right, bottom)
                })
                
                logging.info(f"  ‚úÇÔ∏è  Chunk [{row},{col}]: {right-left}√ó{bottom-top}px")
        
        return chunks
    
    def ocr_chunk(self, chunk_data, chunk_id):
        """OCR m·ªôt chunk"""
        try:
            response = self.client.chat(
                model=self.model_name,
                messages=[{
                    'role': 'user',
                    'content': 'Free OCR.',
                    'images': [chunk_data['bytes']]
                }],
                options={'temperature': 0.0},
                keep_alive=self.keep_alive
            )
            
            text = response['message']['content']
            
            # Parse grounding tags if any
            import re
            pattern = r'<\|ref\|\>(.*?)<\|/ref\|\>\s*<\|det\|\>(.*?)<\|/det\|\>'
            matches = re.findall(pattern, text, re.DOTALL)
            if matches:
                text = '\n'.join([match[0] for match in matches])
            
            return {
                'chunk_id': chunk_id,
                'position': chunk_data['position'],
                'text': text
            }
            
        except Exception as e:
            logging.error(f"‚ùå Chunk {chunk_id} failed: {e}")
            return {
                'chunk_id': chunk_id,
                'position': chunk_data['position'],
                'text': ''
            }
    
    def merge_results(self, chunk_results, rows, cols):
        """
        Gh√©p k·∫øt qu·∫£ theo th·ª© t·ª± chunks
        """
        # Sort by position (row, col)
        sorted_results = sorted(chunk_results, key=lambda x: x['position'])
        
        # Merge row by row
        merged_text = []
        current_row = 0
        row_text = []
        
        for result in sorted_results:
            row, col = result['position']
            
            if row != current_row:
                # New row, merge previous row
                if row_text:
                    merged_text.append('\n'.join(row_text))
                row_text = []
                current_row = row
            
            row_text.append(result['text'])
        
        # Add last row
        if row_text:
            merged_text.append('\n'.join(row_text))
        
        return '\n\n'.join(merged_text)
    
    def process_image(self, image_path, rows=2, cols=2, max_workers=4):
        """
        Process ·∫£nh v·ªõi chunked parallel OCR
        
        Args:
            image_path: ƒê∆∞·ªùng d·∫´n ·∫£nh
            rows: S·ªë h√†ng c·∫Øt
            cols: S·ªë c·ªôt c·∫Øt
            max_workers: S·ªë threads song song
        
        Returns:
            K·∫øt qu·∫£ OCR
        """
        if not os.path.exists(image_path):
            return f"‚ùå File not found: {image_path}"
        
        logging.info(f"üì∏ Processing: {image_path}")
        logging.info(f"‚úÇÔ∏è  Splitting into {rows}√ó{cols} = {rows*cols} chunks")
        
        start_time = time.time()
        
        # Step 1: Split image
        chunks = self.split_image(image_path, rows, cols)
        split_time = time.time()
        logging.info(f"‚è±Ô∏è  Split time: {split_time - start_time:.2f}s\n")
        
        # Step 2: Parallel OCR chunks
        logging.info(f"üîÑ Processing {len(chunks)} chunks in parallel ({max_workers} workers)...")
        
        chunk_results = []
        completed = 0
        
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            future_to_chunk = {
                executor.submit(self.ocr_chunk, chunk, i): i
                for i, chunk in enumerate(chunks)
            }
            
            for future in as_completed(future_to_chunk):
                chunk_id = future_to_chunk[future]
                result = future.result()
                chunk_results.append(result)
                completed += 1
                
                row, col = result['position']
                logging.info(f"  [{completed}/{len(chunks)}] ‚úÖ Chunk [{row},{col}]")
        
        ocr_time = time.time()
        logging.info(f"‚è±Ô∏è  OCR time: {ocr_time - split_time:.2f}s\n")
        
        # Step 3: Merge results
        logging.info("üîó Merging chunks...")
        merged_text = self.merge_results(chunk_results, rows, cols)
        
        total_time = time.time() - start_time
        
        logging.info(f"\n‚úÖ TOTAL TIME: {total_time:.2f}s")
        logging.info(f"   Split: {split_time - start_time:.2f}s")
        logging.info(f"   OCR: {ocr_time - split_time:.2f}s")
        logging.info(f"   Merge: {time.time() - ocr_time:.2f}s")
        
        return merged_text

if __name__ == "__main__":
    ocr = ChunkedOCR()
    
    # Test with first image
    test_img = "test_images/bao-cao-ket-qua-thuc-hien-chuong-trinh-giam-sat-nam-2022-cua-tt-hdnd_trongtb-11-07-2023_08h54p4411.07.2023_14h31p10_signed_page_001.png"
    
    if os.path.exists(test_img):
        print("\n" + "="*60)
        print("üß© CHUNKED PARALLEL OCR TEST")
        print("="*60)
        print(f"Mode: 2√ó2 grid = 4 chunks")
        print(f"Workers: 4 (all chunks parallel)")
        print("="*60 + "\n")
        
        result = ocr.process_image(
            test_img,
            rows=2,      # 2 h√†ng
            cols=2,      # 2 c·ªôt
            max_workers=4  # 4 chunks song song
        )
        
        # Save result
        output_file = "chunked_ocr_result.txt"
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(result)
        
        print(f"\nüíæ Result saved to: {output_file}")
        print(f"üìè Text length: {len(result)} characters")
        print("\nFirst 500 characters:")
        print("-"*60)
        print(result[:500])
        print("...")
    else:
        print(f"‚ùå Test image not found: {test_img}")
